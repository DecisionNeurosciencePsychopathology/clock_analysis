# fit behavioral data for all participants who completed emo clock in scanner
# setup model-based fMRI GLM analysis for based on fitted data

library(dependlab)
library(foreach)
library(doSNOW)

setwd(file.path(getMainDir(), "clock_analysis", "fmri"))
source("fsl_sceptic_model.R")
source("glm_helper_functions.R")
##source("r_glm.R")

fit_all_fmri <- function(trial_statistics, fmri_dir=NULL, idexpr=NULL, iddf=NULL, drop_volumes=6, usenative=FALSE, model="sceptic", runpar=FALSE, ncpus=1, ...) {
  if (runpar) {
    require(doSNOW)
    setDefaultClusterOptions(master="localhost") #move away from 10187 to avoid collisions
    clusterobj <- makeSOCKcluster(ncpus)
    registerDoSNOW(clusterobj)
    
    on.exit(try(stopCluster(clusterobj)))
  } else {
    registerDoSEQ()
  }

  #trial_statistics is the full data.frame generated by compile_trial_level_dataframes.R, which contains trial-level information for all subjects
  #split on id to iterate over subjects
  by_subj <- split(trial_statistics, trial_statistics$id)

  # loop over each subject, identify relevant fMRI data, and setup FSL level 1 files
  ll <- foreach(b = iter(by_subj), .inorder=FALSE, .packages=c("dependlab"),
    .export=c("truncateRuns", "r_valueModel", "fsl_sceptic_model", "runFSLCommand") ) %do% {

      ##example location of file on bea_res, which contains scan date
      subid <- b$id[1] #subject id
      #scandate <- sub("^.*/Basic/\\w+/(\\d+)/.*$", "\\1", b, perl=TRUE)  #not currently accessible

      mrfiles <- c() #force clear of mr files over subjects to avoid potential persistence from one subject to the next

      if (!is.null(iddf)) {
        mrmatch <- iddf$mr_dir[iddf$NUM_ID == subid]
      } else {
        ##identify corresponding fmri directory
        mrmatch <- grep(eval(idexpr), list.files(fmri_dir, full.names=TRUE), perl=TRUE, value=TRUE)
      }

      if (length(mrmatch) != 1L) {
        warning("Unable to find fMRI directory for subid: ", subid)
        return(NULL)
      }        
      
      if (usenative==TRUE) { #spatial adaptive smoothing approach (not currently used. see r_glm.R)
        expectdir <- "native_nosmooth"
        ##expectfile <- "nfudktm_clock(\\d+).nii.gz"
        expectfile <- "nfudktm_clock[0-9].nii.gz"
      } else {
        ##expectdir <- "mni_5mm_wavelet"
        expectdir <- "mni_5mm_aroma"
        expectfile <- "nfaswuktm_clock[0-9]_5.nii.gz"
      }
      
      if (! file.exists(file.path(mrmatch, expectdir))) {
        warning("Unable to find preprocessed data ", expectdir, " for subid: ", subid)
        ##next
        return(NULL)
      }
      
      ## Find processed fMRI run-level data for this subject
      ##mrfiles <- list.files(mrmatch, pattern=expectfile, full.names=TRUE, recursive=TRUE)
      ##cat(paste0("command: find ", mrmatch, " -iname '", expectfile, "' -ipath '*", expectdir, "*' -type f\n"))
      mrfiles <- system(paste0("find ", mrmatch, " -iname '", expectfile, "' -ipath '*", expectdir, "*' -type f | sort -n"), intern=TRUE)
      mrfiles <- mrfiles[!grepl("(exclude|bbr_noref|old)", mrfiles, ignore.case=TRUE)] #if exclude is in path/filename, then skip
      ##mrrunnums <- as.integer(sub(paste0(".*", expectfile, "$"), "\\1", mrfiles, perl=TRUE))
      mrrunnums <- as.integer(sub(paste0(".*clock(\\d+)_.*$"), "\\1", mrfiles, perl=TRUE)) #extract run number from file name

      ##NB. If we reorder the mrfiles, then the run numbers diverge unless we sort(mrrunnums). Remove for now for testing
      ##mrfiles <- mrfiles[order(mrrunnums)] #make absolutely sure that runs are ordered ascending

      if (length(mrfiles) == 0L) {
        warning("Unable to find any preprocessed MB files in dir: ", mrmatch)
        return(NULL)
      }

      ##read number of volumes from NIfTI header
      suppressMessages(library(Rniftilib))
      runlengths <- unname(sapply(mrfiles, function(x) { Rniftilib::nifti.image.read(x, read_data=0)$dim[4L] }))
      detach("package:Rniftilib", unload=TRUE) #necessary to avoid dim() conflict with oro.nifti
      
      ## create truncated run files to end analysis 12s after last ITI (or big head movement)
      ## also handle removal of N volumes from the beginning of each run due to steady state magnetization
      mrdf <- truncateRuns(b, mrfiles, mrrunnums, runlengths, drop_volumes=drop_volumes)
      mrfiles <- mrdf$mrfile_to_analyze
      runlengths <- mrdf$last_vol_analysis
      
      message("About to analyze the following files:")
      print(mrfiles)

      b$d_auc <- -1*b$d_auc #invert decay such that higher values indicate greater decay

      #for now, trying out a handful of univariate model-based regressors
      #fsl_sceptic_model(b, "v_max", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      #fsl_sceptic_model(b, "pe_max", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      fsl_sceptic_model(b, "v_chosen", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      fsl_sceptic_model(b, "v_entropy", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      #fsl_sceptic_model(b, "v_sd", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      fsl_sceptic_model(b, "d_auc", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      #fsl_sceptic_model(b, "d_sd", mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      
      ##results from Mean SCEPTIC regressor correlation.pdf indicate that regressors for vchosen, ventropy_decay_matlab, dauc, and pemax are
      ##reasonably uncorrelated. The worst is dauc with vchosen (mean r = -0.31), which makes sense that as learning progresses, chosen values
      ##are higher and there is less residue to decay. These 4 regressors are also of greatest theoretical interest
      
      #fsl_sceptic_model(b, "v_chosen", "v_entropy", "d_auc", "pe_max")],
      #fsl_sceptic_model(b, "v_chosen", "v_entropy", "d_auc", "pe_max", "v_time"), mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)

      #model without time-varying value signal
      fsl_sceptic_model(b, c("v_chosen", "v_entropy", "d_auc", "pe_max"), mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...)
      fsl_sceptic_model(b, c("v_chosen", "v_entropy_func", "d_auc", "pe_max"), mrfiles, runlengths, mrrunnums, run=FALSE, drop_volumes=drop_volumes, ...) #entropy of value function, not basis weights

    }
  
    message("completed processing of subject: ", subid)
    cat("\n\n\n")
}

#N.B. in examining initial results from single subject analyses, it is clear that steady state magnetization is not achieved by the first volume acquired
#ICA analysis suggests that it takes up to 6 volumes to reach steady state, and the rel and mean uncertainty maps are being adversely affected by this problem
#because they also start high and decay... Mean uncertainty was consequently soaking up a huge amount of CSF in activation maps.
#Because the first presentation occurs at 8 seconds, it seems fine to drop 6 volumes (6s) 

#Jun2017: further ICAs on these data do not suggest a long steady-state problem. Drop 2 volumes for good measure


#SCEPTIC MMClock Fit
#trial_df <- read.csv("/gpfs/group/mnh5174/default/temporal_instrumental_agent/clock_task/vba_fmri/vba_out/compiled_outputs/mmclock_fmri_decay_factorize_mfx_trial_statistics.csv.gz")
trial_df <- read.csv("/gpfs/group/mnh5174/default/temporal_instrumental_agent/clock_task/vba_fmri/vba_out/compiled_outputs/mmclock_fmri_decay_mfx_trial_statistics.csv.gz")
fit_all_fmri(trial_statistics=trial_df,
  fmri_dir="/gpfs/group/mnh5174/default/MMClock/MR_Proc",
  idexpr=expression(subid), ##MMClock/LunaID format: 10637_20140302
  model="sceptic", usepreconvolve=TRUE, runpar=FALSE, ncpus=1, spikeregressors=FALSE, drop_volumes=2) #parmax1 rescales to 1.0 max
#model="sceptic", usepreconvolve=TRUE, parmax1=TRUE, runpar=TRUE, ncpus=20, spikeregressors=FALSE, drop_volumes=2) #parmax1 rescales to 1.0 max


## I have now converted all SPECC MR directory names to all lower case to allow for match on case-sensitive filesystem and to make the naming consistent
idfile <- "/gpfs/group/mnh5174/default/SPECC/SPECC_Participant_Info.csv"
idinfo <- read.csv(idfile)
library(dplyr)
options(dplyr.width=200)
idinfo <- idinfo %>% rowwise() %>% mutate(mr_dir=ifelse(LunaMRI==1,
  paste0("/gpfs/group/mnh5174/default/MMClock/MR_Proc/", Luna_ID, "_", format((as.Date(ScanDate, format="%Y-%m-%d")), "%Y%m%d")), #convert to Date, then reformat YYYYMMDD
  paste0("/gpfs/group/mnh5174/default/SPECC/MR_Proc/", tolower(SPECC_ID), "_", tolower(format((as.Date(ScanDate, format="%Y-%m-%d")), "%d%b%Y"))))) %>% ungroup()

##verify that mr_dir is present as expected
idinfo$dirfound <- file.exists(idinfo$mr_dir)
subset(idinfo, dirfound==FALSE)

##subject CSVs in subjects/SPECC are names according to numeric SPECC_ID
##need to use idinfo data.frame to line up with MMClock, look in Luna dir as needed, etc.
#need SPECC here...
#trial_df <- read.csv("/gpfs/group/mnh5174/default/temporal_instrumental_agent/clock_task/vba_fmri/vba_out/compiled_outputs/mmclock_fmri_decay_factorize_mfx_trial_statistics.csv.gz")
fit_all_fmri(trial_statistics=trial_df, iddf = idinfo, model="sceptic", usepreconvolve=TRUE, parmax1=TRUE, runpar=FALSE, ncpus=1) #rescale to 1.0 max
